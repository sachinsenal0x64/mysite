"use strict";
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
const path_1 = require("path");
const Worker_1 = require("./Worker");
const assert_1 = __importDefault(require("assert"));
const EdgeFunctionWorkerParams_1 = __importDefault(require("./EdgeFunctionWorkerParams"));
const node_fetch_1 = __importDefault(require("node-fetch"));
const EdgeFunctionResponse_1 = __importDefault(require("./EdgeFunctionResponse"));
const log_1 = __importDefault(require("../../log"));
const Serializer_1 = require("./Serializer");
const buffer_1 = require("buffer");
const EdgeFunctionFetchError_1 = __importDefault(require("./EdgeFunctionFetchError"));
const https_1 = require("https");
// The size of the exchange buffer used for exchanging the data between the main thread and the worker thread.
// Arbitrarily set to 50MB as assumed sufficient enough for most requests. If the size is exceeded, the worker
// will throw an error.
const EXCHANGE_BUFFER_SIZE = 50000000;
// In order to replicate the cold start vs warm start behavior of Sailfish, we
// track the wasmInitialMemory buffer. When this is undefined then we are in a
// cold start and need to run the EdgeFunction's init() and run(). When
// wasmInitialMemory is defined then we are in a warm start and we can skip the
// init() and just call run(). The EdgeFunction.run() calls writeWasnInitialMemory()
// on cold start, after init(), to set the wasmInitialMemory buffer. The
// wasmInitialMemory is a global static so it can be used across multiple
// instances of EdgeFunctionsWorkerManager. The wasmInitialMemory is posted to
// the EdgeFunction's parent.run() so it can be set across worker threads.
// When the user's code is rebuilt, we reset the wasmInitialMemory to undefined.
let wasmInitialMemory;
class EdgeFunctionsWorkerManager {
    constructor(context, rawBody, path, sysVars, envVars, usrVars, httpVars) {
        this.readyResponses = [];
        this.outstandingFetchesCount = 0;
        this.workerIsWaiting = false;
        this.context = context;
        this.semaphore = new Int32Array(new SharedArrayBuffer(Int32Array.BYTES_PER_ELEMENT * 1));
        this.exchangeBuffer = new SharedArrayBuffer(Int8Array.BYTES_PER_ELEMENT * EXCHANGE_BUFFER_SIZE);
        this.dataLength = new Int32Array(new SharedArrayBuffer(Int32Array.BYTES_PER_ELEMENT * 1));
        this.channel = new MessageChannel();
        const workerData = {
            semaphore: this.semaphore,
            exchangeBuffer: this.exchangeBuffer,
            exchangeBufferSize: EXCHANGE_BUFFER_SIZE,
            dataLength: this.dataLength,
            params: new EdgeFunctionWorkerParams_1.default(context.getRequest(), rawBody, path, sysVars, envVars, usrVars, httpVars, context.propertyContext.origins),
        };
        this.worker = new Worker_1.Worker((0, path_1.join)(__dirname, this.getWorkerFilename()));
        // Unlike NodeJS worker_threads, the web workers API in browser does not
        // support passing data to worker via options argument of the constructor.
        // Instead, we send workerData as a message named 'init' command.
        this.worker.postMessage({
            command: 'init',
            workerData,
        });
        Atomics.store(this.semaphore, 0, 0);
    }
    // We select the worker file based on the environment. The "./EdgeFunctionBrowserWorker.js" file is used in the browser.
    // Both files are generated from the same EdgeFunctionWorker.ts source file,
    // but the browser version is bigger and bundled with libraries that ensures compatibility.
    getWorkerFilename() {
        return typeof window === 'undefined'
            ? './EdgeFunctionWorker.js'
            : './EdgeFunctionBrowserWorker.js';
    }
    async runEdgeFunction() {
        const textDecoder = new TextDecoder();
        return new Promise((resolve, reject) => {
            // Receives messages from the worker thread in a form of an array of arguments.
            // The first argument is always `type` of the message, with the rest of the arguments
            // being the actual message data, also sent as an array.
            // @ts-ignore
            this.channel.port2.onmessage = (event) => {
                var _a, _b, _c, _d;
                const message = event.data;
                const type = message.shift();
                switch (type) {
                    case 'done-response': {
                        const response = message.shift();
                        this.worker.terminate();
                        const edgeResponse = new EdgeFunctionResponse_1.default(response);
                        resolve(edgeResponse);
                        break;
                    }
                    case 'done-error': {
                        const error = message.shift();
                        this.worker.terminate();
                        // We reject with the error object (or whatever!) that we got from the worker thread
                        // so that we show its stack trace (which points to the actual point of failure) rather than
                        // mask it with manager's stack trace which will always be this handler and is thus useless.
                        reject(error);
                        break;
                    }
                    case 'done-exception': {
                        const panicString = message.shift();
                        this.worker.terminate();
                        reject(new Error(panicString));
                        break;
                    }
                    case 'error': {
                        const error = message.shift();
                        this.worker.terminate();
                        reject(new Error(error));
                        break;
                    }
                    case 'stdout': {
                        const buffer = message.shift();
                        (_b = (_a = this.context) === null || _a === void 0 ? void 0 : _a.stdout) === null || _b === void 0 ? void 0 : _b.write(buffer);
                        break;
                    }
                    case 'stderr': {
                        const buffer = message.shift();
                        (_d = (_c = this.context) === null || _c === void 0 ? void 0 : _c.stderr) === null || _d === void 0 ? void 0 : _d.write(buffer);
                        break;
                    }
                    case 'wasmInitialMemory': {
                        const buffer = message.shift();
                        wasmInitialMemory = buffer;
                        break;
                    }
                    case 'wasmClearMemory': {
                        wasmInitialMemory = undefined;
                        break;
                    }
                    case 'debug': {
                        // Ignore the debug messages as they are only relevant for internal troubleshooting.
                        // If you need to troubleshoot a problem, the writing the received message is easy.
                        const buffer = message.shift();
                        log_1.default.debug(textDecoder.decode(buffer));
                        break;
                    }
                    case 'fetch': {
                        const requestId = message.shift();
                        this.issueFetch(requestId, ...message);
                        break;
                    }
                    case 'waiting': {
                        // Signals to the main thread that the worker is waiting for a message.
                        // If any response is ready, send it to the worker immediately.
                        this.workerIsWaiting = true;
                        // If there are no pending responses and no outstanding fetches, then
                        // the worker has made a mistake and should not have waited. Instead
                        // of it waiting forever, we wake it up setting the response to error
                        // of our own.
                        if (this.readyResponses.length === 0 && this.outstandingFetchesCount === 0) {
                            this.addReadyResponse({
                                error: new Error('Bad wait: no outstanding fetches or pending responses'),
                            });
                            return;
                        }
                        if (this.readyResponses.length > 0) {
                            this.sendNextReadyResponse();
                            return;
                        }
                        break;
                    }
                    default:
                        throw new Error(`Unknown message type: ${type}`);
                }
            };
            this.worker.postMessage({
                command: 'run',
                port: this.channel.port1,
                wasmInitialMemory: wasmInitialMemory,
            }, [
                //@ts-ignore
                this.channel.port1,
            ]);
        });
    }
    /// Issues a fetch request that was serialized from the worker thread.
    async issueFetch(requestId, ...fetchArgs) {
        var _a, _b, _c;
        ++this.outstandingFetchesCount;
        // Sailfish does not follow redirects, so the CLI EdgeFunctions need to emulate that.
        // Our QuickJs implements redirect on top of this 'basic' Sailfish type of fetch.
        const [url, options] = fetchArgs;
        options.redirect = 'manual';
        // Update the URL based on fetch origin and local overrides
        let updatedUrl = new URL(url);
        if (options.fetchOrigin === undefined) {
            throw new Error('Fetch failed: request.fetchOrigin is undefined');
        }
        let fetchOrigin = options.fetchOrigin;
        if (fetchOrigin.override_host_header) {
            options.headers['host'] = fetchOrigin.override_host_header;
        }
        const hosts = fetchOrigin.hosts;
        if (hosts === undefined) {
            throw new Error('Fetch failed: request.fetchOrigin.hosts is undefined');
        }
        const randomHostIndex = Math.floor(Math.random() * hosts.length);
        const randomHost = hosts[randomHostIndex];
        // OriginBackends.location is either a:
        // * Single Hostname string
        // * Array of Hostname string
        // * Array of object with {Port, Hostname}
        // If we get an array, we choose a random one from it.
        let location = randomHost.location;
        if (location === undefined) {
            throw new Error(`Fetch failed: request.fetchOrigin.hosts[${randomHostIndex}].location is undefined`);
        }
        let scheme = randomHost.scheme || 'match';
        if (!['match', 'http', 'https'].includes(scheme)) {
            throw new Error(`Fetch failed: request.fetchOrigin.hosts[${randomHostIndex}].scheme must be one of 'match', 'http', 'https'`);
        }
        if (scheme === 'match') {
            scheme = updatedUrl.protocol === 'https:' ? 'https' : 'http';
        }
        updatedUrl.protocol = scheme + ':';
        // Remove any custom port from the original request URL (e.g. http://localhost:3001/something)
        // because in production either the standard port is used which based on the URL scheme
        // (https -> 443) or custom port defined with your origin configuration.
        updatedUrl.port = '';
        if (typeof location === 'string') {
            updatedUrl.hostname = location;
        }
        else if (Array.isArray(location)) {
            // Pick a random location from the array.
            const randomLocation = location[Math.floor(Math.random() * location.length)];
            if (typeof randomLocation === 'string') {
                updatedUrl.hostname = randomLocation;
            }
            else if (typeof randomLocation === 'object') {
                updatedUrl.hostname = randomLocation.hostname;
                if (randomLocation.port) {
                    updatedUrl.port = randomLocation.port.toString();
                }
            }
        }
        // If a port was not explicitly set, set it based on the protocol.
        updatedUrl.port = updatedUrl.port || (updatedUrl.protocol === 'https:' ? '443' : '80');
        // This environment variable allows us to override the upstream host so we can test edge functions
        // against a local web server.
        const upstreamOverride = (_a = process === null || process === void 0 ? void 0 : process.env) === null || _a === void 0 ? void 0 : _a['EDGIO_CLI_UPSTREAM_OVERRIDE'];
        if (upstreamOverride) {
            const upstreamOverrideUrl = new URL(upstreamOverride);
            updatedUrl.protocol = upstreamOverrideUrl.protocol;
            updatedUrl.hostname = upstreamOverrideUrl.hostname;
            updatedUrl.port = upstreamOverrideUrl.port;
            console.warn(`Overriding upstream ${url} with ${updatedUrl} from EDGIO_CLI_UPSTREAM_OVERRIDE`);
        }
        let timeout;
        // NodeJS accepts 0 ms timeouts but we don't.
        if (options.fetchTimeout > 0) {
            const AbortController = globalThis.AbortController || (await Promise.resolve().then(() => __importStar(require('abort-controller'))));
            const controller = new AbortController();
            timeout = setTimeout(() => {
                controller.abort();
            }, options.fetchTimeout);
            options.signal = controller.signal;
        }
        const isHttps = updatedUrl.protocol === 'https:';
        if (isHttps && ((_c = (_b = options.fetchOrigin) === null || _b === void 0 ? void 0 : _b.tls_verify) === null || _c === void 0 ? void 0 : _c.allow_self_signed_certs)) {
            options.agent = new https_1.Agent({
                rejectUnauthorized: false, // This will bypass the certificate validation
            });
        }
        EdgeFunctionsWorkerManager.fetchImpl(updatedUrl.toString(), options)
            .then(async (response) => {
            const body = await response.buffer();
            --this.outstandingFetchesCount;
            // Now that the body has been decoded, remove the content-encoding header,
            // as it is no longer valid. Edge functions always work with decoded content
            // and fetch doesn't even allow access to encoded content but unfortunately
            // leaves this header in the response.
            response.headers.delete('content-encoding');
            this.addReadyResponse({
                requestId,
                response: new EdgeFunctionResponse_1.default({
                    statusCode: response.status,
                    statusMessage: response.statusText,
                    body,
                    headers: response.headers.raw(),
                }),
            });
        })
            .catch(error => {
            --this.outstandingFetchesCount;
            this.addReadyResponse({
                requestId,
                error_id: this.nodeFetchErrorToId(error),
            });
        })
            .finally(() => {
            clearTimeout(timeout);
        });
    }
    nodeFetchErrorToId(error) {
        if (error.name === 'AbortError') {
            return EdgeFunctionFetchError_1.default.TIMEOUT;
        }
        else {
            return EdgeFunctionFetchError_1.default.CONNECT_FAILED;
        }
    }
    addReadyResponse(response) {
        this.readyResponses.push(response);
        this.sendNextReadyResponse();
    }
    async sendNextReadyResponse() {
        // If the worker is waiting, it means it's ready to receive the next response
        // in the shared buffer. This ensures that we don't overwrite the data in the
        // shared buffer before the worker has finished with it.
        if (this.workerIsWaiting) {
            const readyResponse = this.readyResponses.shift();
            this.copyDataToExchangeBuffer(readyResponse);
            this.wakeWorker();
        }
    }
    copyDataToExchangeBuffer(data) {
        (0, assert_1.default)(data);
        // TODO: If the buffer is too large, grow it?
        // TODO: In this case the new buffer would have to be sent to the worker.
        const serializedData = Serializer_1.Serializer.serialize(data);
        // First set the length of the serialized data.
        this.dataLength[0] = serializedData.byteLength;
        // Copy the data into the exchange buffer.
        serializedData.copy(buffer_1.Buffer.from(this.exchangeBuffer));
    }
    /// Wakes the worker that has been synchronously waiting for the next ready response.
    /// For why this is required, read EdgeFunctionWorker.
    wakeWorker() {
        (0, assert_1.default)(this.workerIsWaiting);
        this.workerIsWaiting = false;
        Atomics.store(this.semaphore, 0, 1);
        Atomics.notify(this.semaphore, 0, 1);
    }
    // Allows to replace the default fetch implementation with the mocked one.
    static setFetchImpl(fetchFunc) {
        EdgeFunctionsWorkerManager.fetchImpl = fetchFunc;
    }
    static clearWasmInitialMemory() {
        wasmInitialMemory = undefined;
    }
}
exports.default = EdgeFunctionsWorkerManager;
EdgeFunctionsWorkerManager.fetchImpl = node_fetch_1.default;
