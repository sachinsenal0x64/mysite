"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
const url_1 = require("url");
const http_1 = __importDefault(require("http"));
const https_1 = __importDefault(require("https"));
const BackendFetchError_1 = __importDefault(require("../errors/BackendFetchError"));
const constants_1 = require("../constants");
const random_1 = require("./random");
const log_1 = __importDefault(require("../log"));
const bindParams_1 = __importDefault(require("../utils/bindParams"));
const mergeQueryString_1 = __importDefault(require("../utils/mergeQueryString"));
const net_1 = require("net");
/**
 * Array of response headers that will not be passed over directly from the proxied resource
 *
 * Notes:
 * - transfer-encoding: as it poisons the response which will be formed
 * based on its own transfer-encoding rather than the one received from the Lambda.
 *
 * - content-length: as the actual constant may be changed by buffer proxy
 * (e.g. on moov_debug=true)
 * @private
 */
const IGNORE_RESPONSE_HEADERS = ['transfer-encoding', 'content-length'];
/**
 * @private
 */
class Backend {
    static setImpl(implementation) {
        impl = implementation;
    }
    static create(config, origin) {
        return new impl(config, origin);
    }
    constructor(config, origin) {
        this.config = config;
        this.origin = origin;
        this.hostHeader = origin.override_host_header;
    }
    /**
     * Sends a request using the proxy.
     * @param req The request being sent.
     * @param res The response for the request.
     * @param options Options for this fetch request.
     */
    async fetch(req, res, options = {}) {
        // Create url for proxy with query params added if existing
        const url = this.getProxyTarget(req);
        const requestOptions = this.getProxyRequestOptions(url, req, options);
        log_1.default.debug('[Backend]', 'fetch', requestOptions);
        return new Promise((resolve, reject) => {
            const lib = url.protocol === 'https:' ? https_1.default : http_1.default;
            let metadataApplied = false;
            const upstreamReq = lib.request(requestOptions, upstreamRes => {
                const processMetadata = () => {
                    /**
                     * Message can end without any data event, therefore we map in both cases.
                     *
                     * Tried to use 'readable' event for detection of receiving headers,
                     * but 'data' event then stops working, so has to be done through this bool.
                     */
                    if (!metadataApplied) {
                        metadataApplied = true;
                        Object.entries(upstreamRes.headers)
                            .filter(([name]) => !IGNORE_RESPONSE_HEADERS.includes(name.toLowerCase()))
                            .forEach(([name, value]) => {
                            try {
                                res.setHeader(name, value);
                            }
                            catch (e) {
                                log_1.default.warn(`Could not relay upstream response header ${name} with value ${value}`, e);
                            }
                        });
                        res.statusCode = upstreamRes.statusCode;
                        res.statusMessage = upstreamRes.statusMessage;
                        log_1.default.debug('proxy', `[${res.statusCode} ${res.statusMessage}]`, url);
                    }
                };
                upstreamRes
                    .on('data', async (chunk) => {
                    try {
                        processMetadata();
                        // we need to await writes, as we could do some processing that could be blocking (eg. running some simulator mods)
                        // also, there's a possibility an error can occur during write, therefore we have to catch it to avoid uncaught errors, and simulator continuation
                        await res.write(chunk);
                    }
                    catch (e) {
                        reject(e);
                        upstreamRes.destroy();
                    }
                })
                    .on('end', async () => {
                    try {
                        if (upstreamRes.complete) {
                            processMetadata();
                            // do not end the response if the status code is 416 (Range Not Satisfiable)
                            await res.end();
                            // we need to wait for flush for cases, where error occurs during res.write
                            await res.waitForFlush();
                            resolve();
                        }
                    }
                    catch (e) {
                        reject(e);
                        upstreamRes.destroy();
                    }
                })
                    .on('error', 
                /* istanbul ignore next */ e => {
                    reject(new BackendFetchError_1.default(e));
                })
                    // Closing the connection before the response is complete
                    // has different behaviours depending on NodeJs version
                    // - node 12: triggers a 'close' event on the Request and Response, and an 'end' event on Response in between
                    // - node 14: triggers a 'close' event on the Request and Response, but no 'end' event on Response anymore
                    // - node 16: triggers a 'close' event on the Request and Response and an "aborted" error on Response in between
                    // See playground at https://runkit.com/adrien-k/aborted-res-error
                    //
                    // We take the most compatible approach, although in v16 and above this should be caught by the 'error' event.
                    /* istanbul ignore next */
                    .on('close', 
                /* istanbul ignore next */ () => {
                    if (!upstreamRes.complete) {
                        reject(new BackendFetchError_1.default(new Error('The connection was terminated while the message was still being sent')));
                    }
                });
            });
            upstreamReq.on('error', e => reject(new BackendFetchError_1.default(e)));
            upstreamReq.end(req.rawBody);
        });
    }
    /**
     * Returns proxy configuration for http-proxy
     * @returns proxy target url
     */
    getProxyTarget(req) {
        let location;
        if (Array.isArray(this.config.location)) {
            location = (0, random_1.getRandomElement)(this.config.location);
        }
        else {
            location = this.config.location;
        }
        if (typeof location === 'string') {
            location = { hostname: location };
        }
        const { hostname, port } = location;
        const protocol = hostname.match(/^(127.0.0.1|localhost)(:\d+)?$/) ? 'http' : 'https';
        const host = `${hostname}${port ? `:${port}` : ''}`;
        const parsed = (0, url_1.parse)(`${protocol}://${host}${req.url}`, true);
        // Force insecure protocol if header is present
        if (req.getHeader(constants_1.HTTP_HEADERS.xEdgeProtocol) === 'http') {
            parsed.protocol = 'http:';
        }
        return parsed;
    }
    /**
     * Returns true if the URL points to the local JS backend, otherwise false.
     * @param url
     * @returns
     */
    isLocal(url) {
        return url.hostname === constants_1.JS_BACKEND_HOSTNAME;
    }
    /**
     * Returns proxy configuration object for node-fetch
     * @param originUrl
     * @param req
     * @param options
     */
    getProxyRequestOptions(originUrl, req, options = {}) {
        var _a, _b, _c;
        let agent = null;
        if (((_a = this.origin.tls_verify) === null || _a === void 0 ? void 0 : _a.allow_self_signed_certs) && originUrl.protocol === 'https:') {
            // For self signed cert fix on local development S3 bucket
            agent = new https_1.default.Agent({ rejectUnauthorized: false });
        }
        let pathWithQuery = (_b = originUrl.path) !== null && _b !== void 0 ? _b : '/';
        // Update the path and merge the query params
        // from the old path together with the params from the new path
        if (options === null || options === void 0 ? void 0 : options.path) {
            const updatedPathWithQuery = (0, bindParams_1.default)(typeof options.path === 'function' ? options.path() || '' : options.path, req.params);
            pathWithQuery = (0, mergeQueryString_1.default)(pathWithQuery !== null && pathWithQuery !== void 0 ? pathWithQuery : '', updatedPathWithQuery);
        }
        // Remove empty search query param values
        if ((options === null || options === void 0 ? void 0 : options.removeEmptySearchParamValues) && originUrl.path) {
            pathWithQuery = pathWithQuery === null || pathWithQuery === void 0 ? void 0 : pathWithQuery.replace(/=(?=&|$)/gm, '');
        }
        const upstreamHeaders = {
            ...req.headers,
            // Add additional request headers
            ...((_c = options === null || options === void 0 ? void 0 : options.headers) !== null && _c !== void 0 ? _c : {}),
            // In order for TLS verification to work, we should avoid using downstream host header.
            // We need to try to use the override_host_header property first, then origin hostname from location in case it's domain,
            // and then fallback to downstream host header.
            host: this.hostHeader /* origins.override_host_header from edgio.config.js */ ||
                (!(0, net_1.isIP)(originUrl.hostname)
                    ? originUrl.host
                    : undefined) /* origins.hosts.location from edgio.config.js in case it's domain */ ||
                req.headers['host'] /* downstream host header */,
        };
        if (this.isLocal(originUrl)) {
            // Some libraries, like [is-https](https://github.com/unjs/is-https#behaviour), rely on x-forwarded-proto
            // to determine if the source request was made securely. This is notably used by Vue Storefront 2. Before
            // we added this header, API requests made by Vue Storefront 2 from the cloud would attempt to reenter Edgio
            // using an http POST, which would be redirected to an https GET, which would cause an infinite loop and soaring lambda costs.
            // Note that we only add x-forwarded-proto for local requests, which never happen over TLS. For remote requests, TLS is used
            // when the downstream request used TLS. We've chosen to do this in order to avoid altering the public behavior of Edgio, which
            // has never sent x-forwarded-proto to origins.
            upstreamHeaders['x-forwarded-proto'] = req.secure ? 'https' : 'http';
        }
        // @ts-ignore
        return {
            ...originUrl,
            path: pathWithQuery,
            method: req.method,
            // first byte timeout should be available here as it is forced by
            // ajv on routes matchers
            timeout: this.config.firstByteTimeout || 0,
            agent,
            body: req.rawBody,
            headers: upstreamHeaders,
        };
    }
}
exports.default = Backend;
let impl = Backend;
